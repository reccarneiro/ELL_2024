{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cccb830c-6e5a-4584-ba4b-0e3aec59a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functions import *\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm \n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "X_used, Y = get_data(42)\n",
    "n = X_used.shape[0]\n",
    "\n",
    "grid_size = 50\n",
    "a_grid = np.linspace(np.min(X_used.age), np.max(X_used.age), grid_size)\n",
    "w_grid = np.linspace(np.min(X_used.hh_inc), np.max(X_used.hh_inc), grid_size)\n",
    "xv, wv = np.meshgrid(a_grid, w_grid, indexing='ij')\n",
    "\n",
    "X_used_cnst = sm.add_constant(X_used)\n",
    "model = sm.OLS(Y,X_used_cnst)\n",
    "results = model.fit()\n",
    "# results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8e26ed-30d9-4485-a999-b1a800cce2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TABLE ALREADY EXISTS\n"
     ]
    }
   ],
   "source": [
    "# Make Database\n",
    "database_name = 'database_happiness_PL.db'\n",
    "con = sqlite3.connect(os.path.join('Results', database_name))\n",
    "cur = con.cursor()\n",
    "\n",
    "res = cur.execute(\"\"\"SELECT name FROM sqlite_master WHERE type='table'\"\"\")\n",
    "table_names = res.fetchall()\n",
    "if ~np.isin('PL', table_names):\n",
    "    print(\"CREATE NEW DATABASE TABLE\")\n",
    "    cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS PL(\n",
    "                Method TEXT NOT NULL,\n",
    "                Model TEXT NOT NULL,\n",
    "                Parameter_v TEXT NOT NULL,\n",
    "                Parameter_y TEXT NOT NULL,\n",
    "                Seed INTEGER NOT NULL,\n",
    "                Treatment TEXT NOT NULL,\n",
    "                Control_1 TEXT NOT NULL,\n",
    "                Control_2 TEXT NOT NULL,\n",
    "                Value REAL NOT NULL,\n",
    "                Con_val_1 REAL NOT NULL,\n",
    "                Con_val_2 REAL NOT NULL,\n",
    "                PRIMARY KEY (Method, Model, Seed, Treatment, Control_1, Control_2))\"\"\")\n",
    "    con.commit()\n",
    "else:\n",
    "    print(\"DATABASE TABLE ALREADY EXISTS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59e6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1  # Bandwidth parameter\n",
    "weights = np.zeros((n, grid_size))\n",
    "for i in range(grid_size):\n",
    "    u = np.abs(X_used['hh_inc'].values - w_grid[i])/h\n",
    "    val = Gaussian(u)\n",
    "    weights[:,i] = val/np.sum(val)\n",
    "\n",
    "characteristic_names = ['zerotofive','sixtotwenty','grp','home_own','gender','isHHH',\n",
    "                        'live_together','work','get_social_benefit',\n",
    "                        'got_social_benefit','religion','marriage','health',\n",
    "                        'exercise','smoke','alcohol']\n",
    "\n",
    "ATE_names = ['zerotofive','sixtotwenty','grp','home_own','gender','isHHH',\n",
    "                        'live_together','work','get_social_benefit',\n",
    "                        'got_social_benefit','religion','marriage','health',\n",
    "                        'exercise','smoke','alcohol']\n",
    "\n",
    "plot_names = ['Baby - No Baby', 'Teenager - No Teenager', 'Grandparents - No Grandparents','Homeowner - Lease',\n",
    "              'Female - Male', 'Head - Not Head', 'Live Together - Separate', \n",
    "              'Work - No Work','Receive Social Insurance - Has Never Received', 'Had Received Social Insurance - Has Never Received',\n",
    "              'Religion - No Religion','Married - Not Married', 'Health',\n",
    "              'Exercise', 'Smoke - No Smoke', 'Alcohol - No Alcohol']\n",
    "\n",
    "n_jobs = 10\n",
    "# seed_list = [42, 43, 44, 45, 46]\n",
    "seed_list = [44, 45, 46]\n",
    "CV_grid_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f556372a-03c6-489e-9bdb-7befbc9cf04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zerotofive\n",
      "13\n",
      "7\n",
      "sixtotwenty\n",
      "13\n",
      "7\n",
      "grp\n",
      "13\n",
      "7\n",
      "home_own\n",
      "13\n",
      "7\n",
      "gender\n",
      "13\n",
      "7\n",
      "isHHH\n",
      "13\n",
      "7\n",
      "live_together\n",
      "13\n",
      "7\n",
      "work\n",
      "13\n",
      "7\n",
      "get_social_benefit\n",
      "13\n",
      "7\n",
      "got_social_benefit\n",
      "13\n",
      "7\n",
      "religion\n",
      "13\n",
      "7\n",
      "marriage\n",
      "13\n",
      "7\n",
      "health\n",
      "13\n",
      "7\n",
      "exercise\n",
      "13\n",
      "7\n",
      "smoke\n",
      "13\n",
      "7\n",
      "alcohol\n",
      "13\n",
      "7\n",
      "zerotofive\n",
      "13\n",
      "7\n",
      "sixtotwenty\n",
      "13\n",
      "7\n",
      "grp\n",
      "13\n",
      "7\n",
      "home_own\n",
      "13\n",
      "7\n",
      "gender\n",
      "13\n",
      "7\n",
      "isHHH\n",
      "13\n",
      "7\n",
      "live_together\n",
      "13\n",
      "7\n",
      "work\n",
      "13\n",
      "7\n",
      "get_social_benefit\n",
      "13\n",
      "7\n",
      "got_social_benefit\n",
      "13\n",
      "7\n",
      "religion\n",
      "13\n",
      "7\n",
      "marriage\n",
      "13\n",
      "7\n",
      "health\n",
      "13\n",
      "7\n",
      "exercise\n",
      "13\n",
      "7\n",
      "smoke\n",
      "13\n",
      "7\n",
      "alcohol\n",
      "13\n",
      "7\n",
      "zerotofive\n",
      "13\n",
      "7\n",
      "sixtotwenty\n",
      "13\n",
      "7\n",
      "grp\n",
      "13\n",
      "7\n",
      "home_own\n",
      "13\n",
      "7\n",
      "gender\n",
      "13\n",
      "7\n",
      "isHHH\n",
      "13\n",
      "7\n",
      "live_together\n",
      "13\n",
      "7\n",
      "work\n",
      "13\n",
      "7\n",
      "get_social_benefit\n",
      "13\n",
      "7\n",
      "got_social_benefit\n",
      "13\n",
      "7\n",
      "religion\n",
      "13\n",
      "7\n",
      "marriage\n",
      "13\n",
      "7\n",
      "health\n",
      "13\n",
      "7\n",
      "exercise\n",
      "13\n",
      "7\n",
      "smoke\n",
      "13\n",
      "7\n",
      "alcohol\n",
      "13\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "######################## Debiased ML, Random Forest ########################\n",
    "############################################################################\n",
    "max_depth_list = np.append(np.linspace(1,50,CV_grid_n-1).astype(int),None)\n",
    "err = 0\n",
    "PL_RF = {}\n",
    "PL_RF['Method'] = ['PL']*len(seed_list)*len(characteristic_names)\n",
    "PL_RF['Model'] = ['RF']*len(seed_list)*len(characteristic_names)\n",
    "PL_RF['Parameter_v'] = []\n",
    "PL_RF['Parameter_y'] = []\n",
    "PL_RF['seed'] = []\n",
    "PL_RF['Treatment'] = []\n",
    "PL_RF['Control_1'] = ['hh_inc']*len(seed_list)*len(characteristic_names)\n",
    "PL_RF['Control_2'] = ['age']*len(seed_list)*len(characteristic_names)\n",
    "PL_RF['Value'] = []\n",
    "PL_RF['Con_val_1'] = []\n",
    "PL_RF['Con_val_2'] = []\n",
    "\n",
    "K = 2\n",
    "\n",
    "for seed in seed_list:\n",
    "    divide_idx = [int(i) for i in np.linspace(0,n,K+1)]\n",
    "    for j, characteristic in enumerate(characteristic_names):\n",
    "        print(characteristic)\n",
    "        PL_RF['seed'].append(seed)\n",
    "        PL_RF['Treatment'].append(characteristic)\n",
    "        V_used = X_used[np.append(characteristic,['hh_inc', 'age'])]\n",
    "        W_used = X_used.drop(np.append(characteristic,['hh_inc', 'age']),axis=1)\n",
    "        Y_resi = np.zeros((n,))\n",
    "        V_resi = np.zeros((n,V_used.shape[1]))\n",
    "        for i in range(K):\n",
    "            V_linear = V_used.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "            W_linear = W_used.iloc[divide_idx[i]:divide_idx[i+1],:]\n",
    "            Y_linear = Y.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "\n",
    "            V_nonlinear = V_used.drop(index=V_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            W_nonlinear = W_used.drop(index=W_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            Y_nonlinear = Y.drop(index=Y.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_RF = np.zeros((len(max_depth_list),))\n",
    "                for cv_i, max_depth in enumerate(max_depth_list):\n",
    "                    clf = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=seed, n_jobs=n_jobs)\n",
    "                    scores = cross_val_score(clf, W_nonlinear, V_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_RF[cv_i] = np.mean(scores)\n",
    "                # if CV_error_RF.argmax()==len(max_depth_list)-2:\n",
    "                #     err = err+1\n",
    "                #     raise ValueError('Tuning parameter at boundary')\n",
    "                max_depth_v = max_depth_list[CV_error_RF.argmax()]\n",
    "                print(max_depth_v)\n",
    "                \n",
    "            RF_model = RandomForestRegressor(n_estimators=100, max_depth=max_depth_v, random_state=seed, n_jobs=n_jobs).fit(W_nonlinear, V_nonlinear)\n",
    "\n",
    "            V_linear_resi = V_linear - RF_model.predict(W_linear)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_RF = np.zeros((len(max_depth_list),))\n",
    "                for cv_i, max_depth in enumerate(max_depth_list):\n",
    "                    clf = RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=seed, n_jobs=n_jobs)\n",
    "                    scores = cross_val_score(clf, W_nonlinear, Y_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_RF[cv_i]=np.mean(scores)\n",
    "                # if CV_error_RF.argmax()==len(max_depth_list)-2:\n",
    "                #     err = err+1\n",
    "                #     raise ValueError('Tuning parameter at boundary')\n",
    "                max_depth_y = max_depth_list[CV_error_RF.argmax()]\n",
    "                print(max_depth_y)\n",
    "                \n",
    "            RF_model = RandomForestRegressor(n_estimators=100, max_depth=max_depth_y, random_state=seed, n_jobs=n_jobs).fit(W_nonlinear, Y_nonlinear)\n",
    "            \n",
    "            Y_linear_resi = Y_linear - RF_model.predict(W_linear)\n",
    "            \n",
    "            V_resi[divide_idx[i]:divide_idx[i+1]] = V_linear_resi.values\n",
    "            Y_resi[divide_idx[i]:divide_idx[i+1]] = Y_linear_resi.values\n",
    "        \n",
    "        if max_depth_v==None:\n",
    "            max_depth_v='None'        \n",
    "        PL_RF['Parameter_v'].append(max_depth_v)\n",
    "        if max_depth_y==None:\n",
    "            max_depth_y='None'        \n",
    "        PL_RF['Parameter_y'].append(max_depth_y)\n",
    "\n",
    "        beta_hat = np.linalg.inv(V_resi.T @ V_resi) @ (V_resi.T @ Y_resi)\n",
    "        PL_RF['Value'].append(beta_hat[0])\n",
    "        PL_RF['Con_val_1'].append(beta_hat[1])\n",
    "        PL_RF['Con_val_2'].append(beta_hat[2])\n",
    "\n",
    "\n",
    "PL_RF = pd.DataFrame(PL_RF)\n",
    "out = PL_RF.values\n",
    "query = ''' insert or replace into PL (Method,Model,Parameter_v,Parameter_y,seed,Treatment,Control_1,Control_2,Value,Con_val_1,Con_val_2) values (?,?,?,?,?,?,?,?,?,?,?) '''\n",
    "cur.executemany(query, out)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec1459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zerotofive\n",
      "34\n",
      "17\n",
      "sixtotwenty\n",
      "34\n",
      "17\n",
      "grp\n",
      "34\n",
      "17\n",
      "home_own\n",
      "17\n",
      "17\n",
      "gender\n",
      "17\n",
      "17\n",
      "isHHH\n",
      "34\n",
      "17\n",
      "live_together\n",
      "17\n",
      "17\n",
      "work\n",
      "17\n",
      "17\n",
      "get_social_benefit\n",
      "17\n",
      "17\n",
      "got_social_benefit\n",
      "34\n",
      "17\n",
      "religion\n",
      "34\n",
      "17\n",
      "marriage\n",
      "34\n",
      "17\n",
      "health\n",
      "17\n",
      "17\n",
      "exercise\n",
      "17\n",
      "17\n",
      "smoke\n",
      "34\n",
      "17\n",
      "alcohol\n",
      "34\n",
      "17\n",
      "zerotofive\n",
      "34\n",
      "17\n",
      "sixtotwenty\n",
      "34\n",
      "17\n",
      "grp\n",
      "34\n",
      "17\n",
      "home_own\n",
      "17\n",
      "17\n",
      "gender\n",
      "17\n",
      "17\n",
      "isHHH\n",
      "34\n",
      "17\n",
      "live_together\n",
      "17\n",
      "17\n",
      "work\n",
      "17\n",
      "17\n",
      "get_social_benefit\n",
      "17\n",
      "17\n",
      "got_social_benefit\n",
      "34\n",
      "17\n",
      "religion\n",
      "34\n",
      "17\n",
      "marriage\n",
      "34\n",
      "17\n",
      "health\n",
      "17\n",
      "17\n",
      "exercise\n",
      "17\n",
      "17\n",
      "smoke\n",
      "34\n",
      "17\n",
      "alcohol\n",
      "34\n",
      "17\n",
      "zerotofive\n",
      "34\n",
      "17\n",
      "sixtotwenty\n",
      "34\n",
      "17\n",
      "grp\n",
      "34\n",
      "17\n",
      "home_own\n",
      "17\n",
      "17\n",
      "gender\n",
      "17\n",
      "17\n",
      "isHHH\n",
      "34\n",
      "17\n",
      "live_together\n",
      "17\n",
      "17\n",
      "work\n",
      "17\n",
      "17\n",
      "get_social_benefit\n",
      "17\n",
      "17\n",
      "got_social_benefit\n",
      "34\n",
      "17\n",
      "religion\n",
      "34\n",
      "17\n",
      "marriage\n",
      "34\n",
      "17\n",
      "health\n",
      "17\n",
      "17\n",
      "exercise\n",
      "17\n",
      "17\n",
      "smoke\n",
      "34\n",
      "17\n",
      "alcohol\n",
      "34\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################################################################\n",
    "########################### Debiased ML, XGB   #############################\n",
    "############################################################################\n",
    "n_estimators_list = np.linspace(1,150,CV_grid_n).astype(int)\n",
    "\n",
    "err = 0\n",
    "PL_XGB = {}\n",
    "PL_XGB['Method'] = ['PL']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGB['Model'] = ['XGB']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGB['Parameter_v'] = []\n",
    "PL_XGB['Parameter_y'] = []\n",
    "PL_XGB['seed'] = []\n",
    "PL_XGB['Treatment'] = []\n",
    "PL_XGB['Control_1'] = ['hh_inc']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGB['Control_2'] = ['age']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGB['Value'] = []\n",
    "PL_XGB['Con_val_1'] = []\n",
    "PL_XGB['Con_val_2'] = []\n",
    "\n",
    "K = 2\n",
    "\n",
    "for seed in seed_list:\n",
    "    divide_idx = [int(i) for i in np.linspace(0,n,K+1)]\n",
    "    for j, characteristic in enumerate(characteristic_names):\n",
    "        print(characteristic)\n",
    "        PL_XGB['seed'].append(seed)\n",
    "        PL_XGB['Treatment'].append(characteristic)\n",
    "        V_used = X_used[np.append(characteristic,['hh_inc', 'age'])]\n",
    "        W_used = X_used.drop(np.append(characteristic,['hh_inc', 'age']),axis=1)\n",
    "        Y_resi = np.zeros((n,))\n",
    "        V_resi = np.zeros((n,V_used.shape[1]))\n",
    "        for i in range(K):\n",
    "            V_linear = V_used.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "            W_linear = W_used.iloc[divide_idx[i]:divide_idx[i+1],:]\n",
    "            Y_linear = Y.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "\n",
    "            V_nonlinear = V_used.drop(index=V_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            W_nonlinear = W_used.drop(index=W_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            Y_nonlinear = Y.drop(index=Y.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_XGB = np.zeros((len(n_estimators_list),))\n",
    "                for n_idx,n_estimators in enumerate(n_estimators_list):\n",
    "\n",
    "                    XGB_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators,\n",
    "                                random_state=seed)\n",
    "                    scores = cross_val_score(XGB_model, W_nonlinear, V_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_XGB[n_idx] = np.mean(scores)\n",
    "                print(n_estimators_list[CV_error_XGB.argmax()])\n",
    "                n_estimators_v = n_estimators_list[CV_error_XGB.argmax()]\n",
    "\n",
    "            XGB_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators_v, random_state=seed).fit(W_nonlinear, V_nonlinear)\n",
    "            V_linear_resi = V_linear - XGB_model.predict(W_linear)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_XGB = np.zeros((len(n_estimators_list),))\n",
    "                for n_idx,n_estimators in enumerate(n_estimators_list):\n",
    "                    XGB_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators,\n",
    "                                random_state=seed)\n",
    "                    scores = cross_val_score(XGB_model, W_nonlinear, Y_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_XGB[n_idx] = np.mean(scores)\n",
    "                # if CV_error_XGB.argmax()==n_est_max-1:\n",
    "                #     err = err+1\n",
    "                #     raise ValueError('Tuning parameter at boundary')\n",
    "                print(n_estimators_list[CV_error_XGB.argmax()])\n",
    "                n_estimators_y = n_estimators_list[CV_error_XGB.argmax()]\n",
    "                \n",
    "            XGB_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators_y,\n",
    "                                random_state=seed).fit(W_nonlinear, Y_nonlinear)\n",
    "            \n",
    "            Y_linear_resi = Y_linear - XGB_model.predict(W_linear)\n",
    "            \n",
    "            V_resi[divide_idx[i]:divide_idx[i+1]] = V_linear_resi.values\n",
    "            Y_resi[divide_idx[i]:divide_idx[i+1]] = Y_linear_resi.values\n",
    "        \n",
    "        PL_XGB['Parameter_v'].append(n_estimators_v)\n",
    "        PL_XGB['Parameter_y'].append(n_estimators_y)\n",
    "\n",
    "        beta_hat = np.linalg.inv(V_resi.T @ V_resi) @ (V_resi.T @ Y_resi)\n",
    "        PL_XGB['Value'].append(beta_hat[0])\n",
    "        PL_XGB['Con_val_1'].append(beta_hat[1])\n",
    "        PL_XGB['Con_val_2'].append(beta_hat[2])\n",
    "\n",
    "\n",
    "PL_XGB = pd.DataFrame(PL_XGB)\n",
    "out = PL_XGB.values\n",
    "query = ''' insert or replace into PL (Method,Model,Parameter_v,Parameter_y,seed,Treatment,Control_1,Control_2,Value,Con_val_1,Con_val_2) values (?,?,?,?,?,?,?,?,?,?,?) '''\n",
    "cur.executemany(query, out)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9871c-4501-4cdf-862a-309780f42e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zerotofive\n",
      "50\n",
      "28\n",
      "sixtotwenty\n",
      "50\n",
      "28\n",
      "grp\n",
      "50\n",
      "28\n",
      "home_own\n",
      "50\n",
      "28\n",
      "gender\n",
      "50\n",
      "28\n",
      "isHHH\n",
      "50\n",
      "44\n",
      "live_together\n",
      "50\n",
      "44\n",
      "work\n",
      "50\n",
      "28\n",
      "get_social_benefit\n",
      "50\n",
      "28\n",
      "got_social_benefit\n",
      "50\n",
      "28\n",
      "religion\n",
      "50\n",
      "39\n",
      "marriage\n",
      "50\n",
      "28\n",
      "health\n",
      "50\n",
      "39\n",
      "exercise\n",
      "50\n",
      "28\n",
      "smoke\n",
      "50\n",
      "39\n",
      "alcohol\n",
      "50\n",
      "28\n",
      "zerotofive\n",
      "50\n",
      "44\n",
      "sixtotwenty\n",
      "50\n",
      "44\n",
      "grp\n",
      "50\n",
      "39\n",
      "home_own\n",
      "50\n",
      "44\n",
      "gender\n",
      "50\n",
      "39\n",
      "isHHH\n",
      "50\n",
      "39\n",
      "live_together\n",
      "50\n",
      "39\n",
      "work\n",
      "50\n",
      "44\n",
      "get_social_benefit\n",
      "50\n",
      "39\n",
      "got_social_benefit\n",
      "50\n",
      "39\n",
      "religion\n",
      "50\n",
      "39\n",
      "marriage\n",
      "50\n",
      "39\n",
      "health\n",
      "50\n",
      "44\n",
      "exercise\n",
      "50\n",
      "39\n",
      "smoke\n",
      "50\n",
      "44\n",
      "alcohol\n",
      "50\n",
      "44\n",
      "zerotofive\n",
      "50\n",
      "50\n",
      "sixtotwenty\n",
      "50\n",
      "39\n",
      "grp\n",
      "50\n",
      "39\n",
      "home_own\n",
      "50\n",
      "39\n",
      "gender\n",
      "50\n",
      "28\n",
      "isHHH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################################################################\n",
    "########################### Debiased ML, XGBs   #############################\n",
    "############################################################################\n",
    "\n",
    "n_estimators_list = np.linspace(1,50,CV_grid_n).astype(int)\n",
    "num_parallel_tree = 100\n",
    "subsample = np.sqrt(X_used.shape[0])/X_used.shape[0]\n",
    "\n",
    "err = 0\n",
    "PL_XGBs = {}\n",
    "PL_XGBs['Method'] = ['PL']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGBs['Model'] = ['XGBs']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGBs['Parameter_v'] = []\n",
    "PL_XGBs['Parameter_y'] = []\n",
    "PL_XGBs['seed'] = []\n",
    "PL_XGBs['Treatment'] = []\n",
    "PL_XGBs['Control_1'] = ['hh_inc']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGBs['Control_2'] = ['age']*len(seed_list)*len(characteristic_names)\n",
    "PL_XGBs['Value'] = []\n",
    "PL_XGBs['Con_val_1'] = []\n",
    "PL_XGBs['Con_val_2'] = []\n",
    "\n",
    "K = 2\n",
    "\n",
    "for seed in seed_list:\n",
    "    divide_idx = [int(i) for i in np.linspace(0,n,K+1)]\n",
    "    for j, characteristic in enumerate(characteristic_names):\n",
    "        print(characteristic)\n",
    "        PL_XGBs['seed'].append(seed)\n",
    "        PL_XGBs['Treatment'].append(characteristic)\n",
    "        V_used = X_used[np.append(characteristic,['hh_inc', 'age'])]\n",
    "        W_used = X_used.drop(np.append(characteristic,['hh_inc', 'age']),axis=1)\n",
    "        Y_resi = np.zeros((n,))\n",
    "        V_resi = np.zeros((n,V_used.shape[1]))\n",
    "        for i in range(K):\n",
    "            V_linear = V_used.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "            W_linear = W_used.iloc[divide_idx[i]:divide_idx[i+1],:]\n",
    "            Y_linear = Y.iloc[divide_idx[i]:divide_idx[i+1]]\n",
    "\n",
    "            V_nonlinear = V_used.drop(index=V_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            W_nonlinear = W_used.drop(index=W_used.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "            Y_nonlinear = Y.drop(index=Y.iloc[divide_idx[i]:divide_idx[i+1]].index,axis=0)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_XGBs = np.zeros((len(n_estimators_list),))\n",
    "                for n_idx,n_estimators in enumerate(n_estimators_list):\n",
    "\n",
    "                    XGBs_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators,\n",
    "                                                  num_parallel_tree = num_parallel_tree, subsample = subsample, random_state=seed)\n",
    "                    scores = cross_val_score(XGBs_model, W_nonlinear, V_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_XGBs[n_idx] = np.mean(scores)\n",
    "                print(n_estimators_list[CV_error_XGBs.argmax()])\n",
    "                n_estimators_v = n_estimators_list[CV_error_XGBs.argmax()]\n",
    "\n",
    "            XGBs_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators_v,\n",
    "                                          num_parallel_tree = num_parallel_tree, subsample = subsample, random_state=seed).fit(W_nonlinear, V_nonlinear)\n",
    "            V_linear_resi = V_linear - XGBs_model.predict(W_linear)\n",
    "\n",
    "            if i == 0:\n",
    "                CV_error_XGBs = np.zeros((len(n_estimators_list),))\n",
    "                for n_idx,n_estimators in enumerate(n_estimators_list):\n",
    "                    XGBs_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators,\n",
    "                                                  num_parallel_tree = num_parallel_tree, subsample = subsample, \n",
    "                                random_state=seed)\n",
    "                    scores = cross_val_score(XGBs_model, W_nonlinear, Y_nonlinear, cv=5, scoring='neg_mean_squared_error')\n",
    "                    CV_error_XGBs[n_idx] = np.mean(scores)\n",
    "                # if CV_error_XGBs.argmax()==n_est_max-1:\n",
    "                #     err = err+1\n",
    "                #     raise ValueError('Tuning parameter at boundary')\n",
    "                print(n_estimators_list[CV_error_XGBs.argmax()])\n",
    "                n_estimators_y = n_estimators_list[CV_error_XGBs.argmax()]\n",
    "                \n",
    "            XGBs_model = xgb.XGBRegressor(n_jobs=n_jobs, tree_method=\"exact\", n_estimators=n_estimators_y,\n",
    "                                          num_parallel_tree = num_parallel_tree, subsample = subsample, \n",
    "                                random_state=seed).fit(W_nonlinear, Y_nonlinear)\n",
    "            \n",
    "            Y_linear_resi = Y_linear - XGBs_model.predict(W_linear)\n",
    "            \n",
    "            V_resi[divide_idx[i]:divide_idx[i+1]] = V_linear_resi.values\n",
    "            Y_resi[divide_idx[i]:divide_idx[i+1]] = Y_linear_resi.values\n",
    "        \n",
    "        PL_XGBs['Parameter_v'].append(n_estimators_v)\n",
    "        PL_XGBs['Parameter_y'].append(n_estimators_y)\n",
    "\n",
    "        beta_hat = np.linalg.inv(V_resi.T @ V_resi) @ (V_resi.T @ Y_resi)\n",
    "        PL_XGBs['Value'].append(beta_hat[0])\n",
    "        PL_XGBs['Con_val_1'].append(beta_hat[1])\n",
    "        PL_XGBs['Con_val_2'].append(beta_hat[2])\n",
    "\n",
    "\n",
    "PL_XGBs = pd.DataFrame(PL_XGBs)\n",
    "out = PL_XGBs.values\n",
    "query = ''' insert or replace into PL (Method,Model,Parameter_v,Parameter_y,seed,Treatment,Control_1,Control_2,Value,Con_val_1,Con_val_2) values (?,?,?,?,?,?,?,?,?,?,?) '''\n",
    "cur.executemany(query, out)\n",
    "con.commit()\n",
    "cur.close()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
